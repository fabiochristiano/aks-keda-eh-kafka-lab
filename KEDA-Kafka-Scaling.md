# KEDA + Kafka/Event Hub: EstratÃ©gias de Escalonamento

## ğŸ“‹ VisÃ£o Geral

Este documento explica como o KEDA funciona com Kafka/Event Hub e as diferenÃ§as importantes em relaÃ§Ã£o ao Service Bus, especialmente no que se refere ao relacionamento entre **partiÃ§Ãµes** e **pods**.

## ğŸ¯ Conceito Fundamental: PartiÃ§Ãµes = Limite de Pods

### âš ï¸ Regra de Ouro do Kafka
```
MÃ¡ximo de Pods Ãšteis = NÃºmero de PartiÃ§Ãµes
```

**Por quÃª?**
- Cada partiÃ§Ã£o pode ser consumida por **apenas 1 consumer** no mesmo Consumer Group
- Pods extras ficam **IDLE** (ociosos) sem partiÃ§Ãµes para consumir
- NÃ£o hÃ¡ ganho de performance com mais pods que partiÃ§Ãµes

## ğŸ”„ Como Funciona o Escalonamento

### CenÃ¡rio Atual: 2 PartiÃ§Ãµes
```yaml
# receiver.yaml (configuraÃ§Ã£o atual)
maxReplicaCount: 20  # âš ï¸ PROBLEMÃTICO!
```

**Resultado prÃ¡tico:**
```
TÃ³pico "orders" (2 partiÃ§Ãµes apenas)
â”œâ”€â”€ Partition 0 â”€â”€â”€â”€ Pod-1 âœ… (ativo)
â”œâ”€â”€ Partition 1 â”€â”€â”€â”€ Pod-2 âœ… (ativo)
â”œâ”€â”€ Pod-3 âŒ (IDLE - sem trabalho)
â”œâ”€â”€ Pod-4 âŒ (IDLE - sem trabalho)
â”œâ”€â”€ ...
â””â”€â”€ Pod-20 âŒ (IDLE - sem trabalho)
```

## ğŸ“Š KEDA vs Service Bus vs Kafka

| Aspecto | Service Bus | Kafka/Event Hub |
|---------|-------------|-----------------|
| **Escalonamento** | Baseado em msgs na fila | Baseado em msgs nÃ£o processadas **POR PARTIÃ‡ÃƒO** |
| **Limite de Consumers** | Ilimitado (competiÃ§Ã£o) | 1 consumer por partiÃ§Ã£o no mesmo grupo |
| **Pods MÃ¡ximos Ãšteis** | Sem limite teÃ³rico | = NÃºmero de partiÃ§Ãµes |
| **DistribuiÃ§Ã£o** | Round-robin entre consumers | 1 partiÃ§Ã£o por consumer |

## ğŸ›ï¸ ConfiguraÃ§Ãµes Recomendadas

### Para 2 PartiÃ§Ãµes (atual):
```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: receiver
spec:
  scaleTargetRef:
    name: receiver
  pollingInterval: 15
  minReplicaCount: 0
  maxReplicaCount: 2  # âœ… Igual ao nÃºmero de partiÃ§Ãµes
  cooldownPeriod: 30
  triggers:
  - type: azure-eventhub
    metadata:
      eventHubName: orders
      consumerGroup: orders-consumer
      unprocessedEventThreshold: "10"
      eventHubNamespace: aks-keda-eh-lab-9zbdqD
```

### Para 5 PartiÃ§Ãµes (escalado):
```yaml
maxReplicaCount: 5  # âœ… Igual ao nÃºmero de partiÃ§Ãµes
```

## ğŸš€ EstratÃ©gia de Escalonamento

### 1ï¸âƒ£ Monitoramento
```bash
# Verificar partiÃ§Ãµes atuais
az eventhubs eventhub show \
  --resource-group aks-keda-eh-kafka-lab \
  --namespace-name aks-keda-eh-kafka-lab-9zbdqD \
  --name orders \
  --query partitionCount

# Monitorar lag por partiÃ§Ã£o
kubectl describe scaledobject receiver -n order
```

### 2ï¸âƒ£ Quando Escalar PartiÃ§Ãµes?

**Sinais de que precisa mais partiÃ§Ãµes:**
- âœ… Lag consistentemente alto (>threshold)
- âœ… 2 pods jÃ¡ estÃ£o no mÃ¡ximo de CPU/Memory
- âœ… Mensagens acumulando mesmo com 2 pods ativos
- âœ… Throughput nÃ£o consegue acompanhar a demanda

**Como identificar:**
```bash
# Ver utilizaÃ§Ã£o dos pods
kubectl top pods -n order -l app=receiver

# Ver mÃ©tricas do KEDA
kubectl get hpa -n order
kubectl describe hpa keda-hpa-receiver -n order
```

### 3ï¸âƒ£ Processo de Escalonamento

```mermaid
graph TD
    A[Msgs Acumulando] --> B{Pods jÃ¡ no mÃ¡ximo?}
    B -->|Sim| C[Aumentar PartiÃ§Ãµes]
    B -->|NÃ£o| D[KEDA escala pods automaticamente]
    C --> E[Atualizar maxReplicaCount]
    C --> F[Atualizar Event Hub partiÃ§Ãµes]
    E --> G[Aplicar receiver.yaml]
    F --> G
    G --> H[Pods se redistribuem automaticamente]
```

## âš¡ Exemplo PrÃ¡tico: Escalonamento de 2 para 5 PartiÃ§Ãµes

### Passo 1: Aumentar partiÃ§Ãµes no Event Hub
```bash
az eventhubs eventhub update \
  --resource-group aks-keda-eh-kafka-lab \
  --namespace-name aks-keda-eh-kafka-lab-9zbdqD \
  --name orders \
  --partition-count 5
```

### Passo 2: Atualizar KEDA
```yaml
# receiver.yaml
maxReplicaCount: 5  # Era 20, agora 5
```

### Passo 3: Aplicar mudanÃ§as
```bash
kubectl apply -f receiver.yaml
```

### Resultado:
```
TÃ³pico "orders" (5 partiÃ§Ãµes)
â”œâ”€â”€ Partition 0 â”€â”€â”€â”€ Pod-1 âœ…
â”œâ”€â”€ Partition 1 â”€â”€â”€â”€ Pod-2 âœ…  
â”œâ”€â”€ Partition 2 â”€â”€â”€â”€ Pod-3 âœ…
â”œâ”€â”€ Partition 3 â”€â”€â”€â”€ Pod-4 âœ…
â””â”€â”€ Partition 4 â”€â”€â”€â”€ Pod-5 âœ…
```

## ğŸ“ˆ MÃ©tricas de Monitoramento

### KPIs Importantes:
1. **Lag por PartiÃ§Ã£o**: Mensagens nÃ£o processadas
2. **Throughput por Pod**: Msgs/segundo processadas
3. **CPU/Memory por Pod**: UtilizaÃ§Ã£o de recursos
4. **Tempo de Rebalanceamento**: Quando pods entram/saem

### Comandos Ãšteis:
```bash
# Ver lag atual
kubectl get scaledobject receiver -n order -o yaml

# Ver pods ativos
kubectl get pods -n order -l app=receiver

# Ver logs de rebalanceamento
kubectl logs -n order -l app=receiver --tail=50 | grep -i "rebalance\|partition"
```

## ğŸ¯ Boas PrÃ¡ticas

### âœ… FaÃ§a:
- Monitore lag por partiÃ§Ã£o regularmente
- Alinhe `maxReplicaCount` com nÃºmero de partiÃ§Ãµes
- Teste escalonamento em ambiente de desenvolvimento
- Considere custos ao aumentar partiÃ§Ãµes (sÃ£o permanentes)

### âŒ Evite:
- `maxReplicaCount` maior que partiÃ§Ãµes
- Mudar partiÃ§Ãµes sem atualizar KEDA
- Escalonamento reativo (muito tarde)
- Reduzir partiÃ§Ãµes (nÃ£o Ã© suportado)

## ğŸ’° ConsideraÃ§Ãµes de Custo

- **PartiÃ§Ãµes sÃ£o permanentes** - nÃ£o podem ser reduzidas
- **Cada partiÃ§Ã£o tem custo** no Azure Event Hub
- **Planeje capacidade** antes de escalar
- **Monitore utilizaÃ§Ã£o** para otimizar custos

## ğŸ”§ Troubleshooting

### Problema: Pods IDLE
```bash
# Verificar distribuiÃ§Ã£o de partiÃ§Ãµes
kubectl exec -it <receiver-pod> -n order -- ps aux
```

### Problema: Lag alto mesmo com pods disponÃ­veis
```bash
# Verificar se Consumer Group estÃ¡ correto
kubectl logs <receiver-pod> -n order | grep "group.id"
```

### Problema: Rebalanceamento constante
```bash
# Verificar estabilidade dos pods
kubectl get pods -n order -w
```

## ğŸ“š Recursos Adicionais

- [KEDA Azure Event Hub Scaler](https://keda.sh/docs/latest/scalers/azure-event-hub/)
- [Kafka Consumer Groups](https://kafka.apache.org/documentation/#intro_consumers)
- [Azure Event Hub Partitioning](https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-scalability#partitions)

---

**ğŸ“ Resumo:** Em Kafka/Event Hub, o nÃºmero de partiÃ§Ãµes Ã© o fator limitante para escalonamento horizontal. Sempre alinhe `maxReplicaCount` com o nÃºmero de partiÃ§Ãµes para otimizar recursos e performance.
